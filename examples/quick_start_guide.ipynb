{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5396ad",
   "metadata": {},
   "source": [
    "# Quick Start Guide (Notebook)\n",
    "\n",
    "Minimal, runnable version of the quick-start example. Toggle sampler flags to run heavier demos; defaults keep execution light. Standard priors are pulled from Discovery's ``priordict_standard`` via ``standard_priors``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed71c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and toggles\n",
    "RUN_NESSAI = True\n",
    "RUN_JAXNS = True\n",
    "RUN_ERYN = True\n",
    "RUN_GPRY = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2783eaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pulsar path: /Users/jeg/Documents/discovery/discovery/src/discovery/../../data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import jax\n",
    "import discovery as ds\n",
    "from discoverysamplers.priors import standard_priors\n",
    "import os\n",
    "import glob\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# Path to a bundled pulsar file (relative to the discovery package install)\n",
    "path_to_discovery = ds.__path__[0]\n",
    "FEATHER_PATH = os.path.join(path_to_discovery, \"../../data\")\n",
    "print(f\"Using pulsar path: {FEATHER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d062729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 2 parameters\n",
      "Parameters: ['B1855+09_efac', 'B1855+09_log10_t2equad']\n"
     ]
    }
   ],
   "source": [
    "# Load pulsar and build a likelihood\n",
    "allpsrs = [ds.Pulsar.read_feather(psrfile) for psrfile in sorted(glob.glob(os.path.join(FEATHER_PATH,'*-[JB]*.feather')))]\n",
    "psr = allpsrs[0]\n",
    "likelihood = ds.PulsarLikelihood([\n",
    "    psr.residuals,\n",
    "    ds.makenoise_measurement_simple(psr),\n",
    "])\n",
    "params = likelihood.logL.params\n",
    "print(f\"Discovered {len(params)} parameters\")\n",
    "print(\"Parameters:\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f155fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard priors:\n",
      "  B1855+09_efac: {'dist': 'uniform', 'min': 0.9, 'max': 1.1}\n",
      "  B1855+09_log10_t2equad: {'dist': 'uniform', 'min': -8.5, 'max': -5.0}\n"
     ]
    }
   ],
   "source": [
    "# Standard priors from discovery (uniform bounds defined in priordict_standard)\n",
    "priors = standard_priors(params)\n",
    "\n",
    "print(\"Standard priors:\")\n",
    "for p in params:\n",
    "    print(f\"  {p}: {priors[p]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8c4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = {\n",
    "    \"B1855+09_log10_t2equad\": -6.517929916655293\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c686e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior with fixed parameters\n",
      "  B1855+09_efac: {'dist': 'uniform', 'min': 0.9, 'max': 1.1}\n",
      "  B1855+09_log10_t2equad: {'dist': 'fixed', 'value': -6.517929916655293}\n"
     ]
    }
   ],
   "source": [
    "# Get the true values for the parameters and fix all but the first two\n",
    "\n",
    "fixed_params = params[1:]\n",
    "for name in fixed_params:\n",
    "    if name in priors:\n",
    "        priors[name] = {\"dist\": \"fixed\", \"value\": true_vals[name]}\n",
    "\n",
    "print(\"Prior with fixed parameters\")\n",
    "for p in params:\n",
    "    print(f\"  {p}: {priors[p]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de22cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B1855+09_log10_t2equad': -6.517929916655293}\n"
     ]
    }
   ],
   "source": [
    "print(true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1d0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood for one random draw: 97446.43448870355\n",
      "\n",
      "Testing edge cases:\n",
      "  efac=0.9: logL=96186.9572927178\n",
      "  efac=0.95: logL=96748.58836262813\n",
      "  efac=1.0: logL=97188.28908331192\n",
      "  efac=1.05: logL=97530.62052096789\n",
      "  efac=1.1: logL=97794.5188412677\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check: draw one sample from the priors and evaluate the likelihood\n",
    "rng = np.random.default_rng(123)\n",
    "sample = {}\n",
    "for name, spec in priors.items():\n",
    "    dist = spec[\"dist\"]\n",
    "    if dist == \"uniform\":\n",
    "        sample[name] = rng.uniform(spec[\"min\"], spec[\"max\"])\n",
    "    elif dist == \"loguniform\":\n",
    "        sample[name] = np.exp(rng.uniform(np.log(spec[\"min\"]), np.log(spec[\"max\"])))\n",
    "    elif dist == \"fixed\":\n",
    "        sample[name] = spec[\"value\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dist in this quick demo: {dist}\")\n",
    "print(\"Log-likelihood for one random draw:\", likelihood.logL(sample))\n",
    "\n",
    "# Test edge cases\n",
    "print(\"\\nTesting edge cases:\")\n",
    "for efac_val in [0.9, 0.95, 1.0, 1.05, 1.1]:\n",
    "    test_sample = {'B1855+09_efac': efac_val, 'B1855+09_log10_t2equad': true_vals['B1855+09_log10_t2equad']}\n",
    "    logL = likelihood.logL(test_sample)\n",
    "    print(f\"  efac={efac_val}: logL={logL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee5d42",
   "metadata": {},
   "source": [
    "## Nessai (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d35959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nessai run skipped due to error: names list has length 1. nessai is not designed to handle one-dimensional models due to limitations imposed by the normalising flow-based proposals it uses. Consider using other methods instead of nessai.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if RUN_NESSAI:\n",
    "    try:\n",
    "        from discoverysamplers.nessai_interface import DiscoveryNessaiBridge\n",
    "        bridge = DiscoveryNessaiBridge(discovery_model=likelihood, priors=priors, jit=True)\n",
    "        results = bridge.run_sampler(\n",
    "            nlive=100,\n",
    "            output=\"output/nessai_demo\", \n",
    "            resume=False\n",
    "        )\n",
    "        print(\"Nessai logZ:\", results[\"logZ\"], \"+/-\", results.get(\"logZ_err\"))\n",
    "    except Exception as exc:\n",
    "        print(\"Nessai run skipped due to error:\", exc)\n",
    "else:\n",
    "    print(\"RUN_NESSAI=False; skipping Nessai demo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38a868",
   "metadata": {},
   "source": [
    "## JAX-NS (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e971ae6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jaxns:Number of Markov-chains set to: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with max_samples=5000:\n",
      "JAX-NS logZ: 97796.52 +/- 0.019\n",
      "Actually used 2700 out of 5000 allocated samples\n",
      "JAX-NS logZ: 97796.52 +/- 0.019\n",
      "Actually used 2700 out of 5000 allocated samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if RUN_JAXNS:\n",
    "    try:\n",
    "        # Force reload the module to pick up changes\n",
    "        import importlib\n",
    "        import discoverysamplers.jaxns_interface\n",
    "        importlib.reload(discoverysamplers.jaxns_interface)\n",
    "        from discoverysamplers.jaxns_interface import DiscoveryJAXNSBridge\n",
    "        \n",
    "        # Create bridge\n",
    "        bridge = DiscoveryJAXNSBridge(discovery_model=likelihood, priors=priors, latex_labels=None, jit=True)\n",
    "        \n",
    "        print(\"Testing with max_samples=5000:\")\n",
    "        results = bridge.run_sampler(nlive=200, max_samples=5000, termination_frac=0.05, rng_seed=0)\n",
    "        \n",
    "        print(f\"JAX-NS logZ: {results['logZ']:.2f} +/- {results['logZerr']:.3f}\")\n",
    "        print(f\"Actually used {results['state'].num_samples} out of 5000 allocated samples\")\n",
    "        \n",
    "    except Exception as exc:\n",
    "        import traceback\n",
    "        print(\"JAX-NS run skipped due to error:\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"RUN_JAXNS=False; skipping JAX-NS demo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2f171",
   "metadata": {},
   "source": [
    "## Eryn MCMC (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23913d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eryn chain shape: (100, 3, 32, 1, 1) (nsteps, ntemps, nwalkers, nleaves, ndim)\n",
      "Sampled parameters: ['B1855+09_efac']\n",
      "Fixed parameters: {'B1855+09_log10_t2equad': -6.517929916655293}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if RUN_ERYN:\n",
    "    try:\n",
    "        from discoverysamplers.eryn_interface import DiscoveryErynBridge\n",
    "        \n",
    "        bridge = DiscoveryErynBridge(model=likelihood, priors=priors)\n",
    "        nwalkers = max(2 * bridge.ndim, 32)\n",
    "        \n",
    "        # Create sampler with parallel tempering (optional)\n",
    "        sampler = bridge.create_sampler(nwalkers=nwalkers, tempering_kwargs=dict(ntemps=3))\n",
    "        \n",
    "        # Run MCMC \n",
    "        bridge.run_sampler(nsteps=100, progress=False)\n",
    "        \n",
    "        # Get samples using the bridge's method\n",
    "        samples = bridge.return_sampled_samples()\n",
    "        print(f\"Eryn chain shape: {samples['chain'].shape} (nsteps, ntemps, nwalkers, nleaves, ndim)\")\n",
    "        print(f\"Sampled parameters: {samples['names']}\")\n",
    "        print(f\"Fixed parameters: {bridge.fixed_param_dict}\")\n",
    "    except Exception as exc:\n",
    "        import traceback\n",
    "        print(\"Eryn run skipped due to error:\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"RUN_ERYN=False; skipping Eryn demo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda3cb3",
   "metadata": {},
   "source": [
    "## GPry via Cobaya (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16452a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pulsar_likelihood:Initialized external likelihood.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pulsar_likelihood] Initialized external likelihood.\n",
      "Original param names: ['B1855+09_efac', 'B1855+09_log10_t2equad']\n",
      "Sanitized param names: ['B1855_09_efac']\n",
      "Sampled (original): ['B1855+09_efac']\n",
      "Fixed (original): ['B1855+09_log10_t2equad']\n",
      "Original param names: ['B1855+09_efac', 'B1855+09_log10_t2equad']\n",
      "Sanitized param names: ['B1855_09_efac']\n",
      "Sampled (original): ['B1855+09_efac']\n",
      "Fixed (original): ['B1855+09_log10_t2equad']\n",
      "Initializing SurrogateModel with the following options:\n",
      "=======================================================\n",
      "* X-preprocessor: NormalizeBounds\n",
      "* y-preprocessor: NormalizeY\n",
      "* GPR kernel:\n",
      "   3.16**2 * RBF(length_scale=0.1)\n",
      "  with hyperparameters (in transformed scale):\n",
      "    -Hyperparameter(name='k1__constant_value', value_type='numeric', bounds=array([[1.e-04, 1.e+06]]), max_length=None, n_elements=1, fixed=False, dynamic=False)\n",
      "    -Hyperparameter(name='k2__length_scale', value_type='numeric', bounds=array([[1.e-05, 1.e+05]]), max_length=None, n_elements=1, fixed=False, dynamic=False)\n",
      "* Noise level: 0.01\n",
      "* Classifiers for infinities: SVM (threshold: 20s)\n",
      "Initialized GPry.\n",
      "===============================================================================\n",
      "| Drawing initial samples.                                                    |\n",
      "===============================================================================\n",
      "Initializing SurrogateModel with the following options:\n",
      "=======================================================\n",
      "* X-preprocessor: NormalizeBounds\n",
      "* y-preprocessor: NormalizeY\n",
      "* GPR kernel:\n",
      "   3.16**2 * RBF(length_scale=0.1)\n",
      "  with hyperparameters (in transformed scale):\n",
      "    -Hyperparameter(name='k1__constant_value', value_type='numeric', bounds=array([[1.e-04, 1.e+06]]), max_length=None, n_elements=1, fixed=False, dynamic=False)\n",
      "    -Hyperparameter(name='k2__length_scale', value_type='numeric', bounds=array([[1.e-05, 1.e+05]]), max_length=None, n_elements=1, fixed=False, dynamic=False)\n",
      "* Noise level: 0.01\n",
      "* Classifiers for infinities: SVM (threshold: 20s)\n",
      "Initialized GPry.\n",
      "===============================================================================\n",
      "| Drawing initial samples.                                                    |\n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 549.98it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVALUATION] (0.042 sec) Evaluated the true log-posterior at 12 location(s), of which 4 returned a finite value.\n",
      "[FIT] (0.051 sec) Fitted GP model with new acquired points, including the surrogate model hyperparameters. 4 finite points were added to the GP regressor. Hyperparameters were fit with 12 restart(s).\n",
      "Warning: Some of the initial training points are very close to each other. This may lead to numerical instability in the GP. Consider increasing the number of initial points or decreasing the volume of your prior.\n",
      "===============================================================================\n",
      "| Iteration 1 (at most 58 left)                                               |\n",
      "| Total truth evals: 12 (4 finite) of 70                                      |\n",
      "===============================================================================\n",
      "1 of the proposed points are already in the training set. Skipping them.\n",
      "[ACQUISITION] (0.032 sec) Proposed 0 point(s) for truth evaluation.\n",
      "Acquisition returned less than half of the requested points. Re-sampling (1 tries remaining)\n",
      "===============================================================================\n",
      "| Iteration 2 (at most 58 left)                                               |\n",
      "| Total truth evals: 12 (4 finite) of 70                                      |\n",
      "===============================================================================\n",
      "1 of the proposed points are already in the training set. Skipping them.\n",
      "[ACQUISITION] (0.02 sec) Proposed 0 point(s) for truth evaluation.\n",
      "Acquisition returned less than half of the requested points. Re-sampling (0 tries remaining)\n",
      "===============================================================================\n",
      "| Iteration 3 (at most 58 left)                                               |\n",
      "| Total truth evals: 12 (4 finite) of 70                                      |\n",
      "===============================================================================\n",
      "1 of the proposed points are already in the training set. Skipping them.\n",
      "[ACQUISITION] (0.017 sec) Proposed 0 point(s) for truth evaluation.\n",
      "Acquisition returning no values after 2 re-tries. Giving up.\n",
      "\n",
      "GPry runner completed successfully!\n",
      "[FIT] (0.051 sec) Fitted GP model with new acquired points, including the surrogate model hyperparameters. 4 finite points were added to the GP regressor. Hyperparameters were fit with 12 restart(s).\n",
      "Warning: Some of the initial training points are very close to each other. This may lead to numerical instability in the GP. Consider increasing the number of initial points or decreasing the volume of your prior.\n",
      "===============================================================================\n",
      "| Iteration 1 (at most 58 left)                                               |\n",
      "| Total truth evals: 12 (4 finite) of 70                                      |\n",
      "===============================================================================\n",
      "1 of the proposed points are already in the training set. Skipping them.\n",
      "[ACQUISITION] (0.032 sec) Proposed 0 point(s) for truth evaluation.\n",
      "Acquisition returned less than half of the requested points. Re-sampling (1 tries remaining)\n",
      "===============================================================================\n",
      "| Iteration 2 (at most 58 left)                                               |\n",
      "| Total truth evals: 12 (4 finite) of 70                                      |\n",
      "===============================================================================\n",
      "1 of the proposed points are already in the training set. Skipping them.\n",
      "[ACQUISITION] (0.02 sec) Proposed 0 point(s) for truth evaluation.\n",
      "Acquisition returned less than half of the requested points. Re-sampling (0 tries remaining)\n",
      "===============================================================================\n",
      "| Iteration 3 (at most 58 left)                                               |\n",
      "| Total truth evals: 12 (4 finite) of 70                                      |\n",
      "===============================================================================\n",
      "1 of the proposed points are already in the training set. Skipping them.\n",
      "[ACQUISITION] (0.017 sec) Proposed 0 point(s) for truth evaluation.\n",
      "Acquisition returning no values after 2 re-tries. Giving up.\n",
      "\n",
      "GPry runner completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if RUN_GPRY:\n",
    "    try:\n",
    "        from discoverysamplers.gpry_interface import DiscoveryGPryCobayaBridge\n",
    "        \n",
    "        bridge = DiscoveryGPryCobayaBridge(\n",
    "            discovery_model=likelihood.logL, \n",
    "            priors=priors, \n",
    "            like_name=\"pulsar_likelihood\",\n",
    "        )\n",
    "        \n",
    "        print(f\"Original param names: {bridge.orig_param_names}\")\n",
    "        print(f\"Sanitized param names: {bridge.sanitized_param_names}\")\n",
    "        print(f\"Sampled (original): {bridge.sampled_names}\")\n",
    "        print(f\"Fixed (original): {bridge.fixed_names}\")\n",
    "        \n",
    "        info, runner = bridge.run_sampler()\n",
    "        print(f\"\\nGPry runner completed successfully!\")\n",
    "    except Exception as exc:\n",
    "        import traceback\n",
    "        print(\"GPry run skipped due to error:\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"RUN_GPRY=False; skipping GPry demo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ef044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
