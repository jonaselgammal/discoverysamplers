{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ecf2d1",
   "metadata": {},
   "source": [
    "# BlackJAX Nested Sampling GPU Performance Testing\n",
    "\n",
    "This notebook tests BlackJAX nested sampling performance on Apple Metal GPU.\n",
    "\n",
    "**Goal**: Find the optimal `num_delete` parameter to maximize GPU utilization.\n",
    "\n",
    "The `num_delete` parameter controls how many live points are replaced in each iteration.\n",
    "Higher values allow more parallel work per iteration, which can better utilize GPU cores.\n",
    "\n",
    "## Setup: Installing JAX Metal\n",
    "\n",
    "If JAX Metal is not installed, run:\n",
    "```bash\n",
    "pip install jax-metal\n",
    "```\n",
    "\n",
    "**Note**: JAX Metal requires macOS 12.0+ and an Apple Silicon (M1/M2/M3) chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check the current JAX setup\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Available devices: {jax.devices()}\")\n",
    "print(f\"Default backend: {jax.default_backend()}\")\n",
    "\n",
    "# Check if Metal is available\n",
    "try:\n",
    "    metal_devices = [d for d in jax.devices() if 'metal' in str(d).lower() or 'gpu' in str(d).lower()]\n",
    "    if metal_devices:\n",
    "        print(f\"\\n✓ Metal GPU available: {metal_devices}\")\n",
    "    else:\n",
    "        print(\"\\n⚠ No Metal GPU detected. You may need to install jax-metal:\")\n",
    "        print(\"  pip install jax-metal\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking devices: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403712e2",
   "metadata": {},
   "source": [
    "## Install jax-metal if needed\n",
    "\n",
    "Uncomment and run the cell below if Metal is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e07df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install jax-metal\n",
    "# !pip install jax-metal\n",
    "\n",
    "# After installing, you may need to restart the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0f031",
   "metadata": {},
   "source": [
    "## Set up the Discovery likelihood\n",
    "\n",
    "We'll use the same 3-pulsar red noise model from the example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import discovery as ds\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Find discovery package location\n",
    "discovery_location = os.path.dirname(ds.__file__)\n",
    "print(f\"Discovery package at: {discovery_location}\")\n",
    "\n",
    "# Load pulsars\n",
    "allpsrs = [ds.Pulsar.read_feather(psrfile) \n",
    "           for psrfile in sorted(glob.glob(f'{discovery_location}/../../data/*-[JB]*.feather'))]\n",
    "print(f\"Loaded {len(allpsrs)} pulsars\")\n",
    "\n",
    "# Use 3 pulsars for testing\n",
    "psrs = allpsrs[:3]\n",
    "\n",
    "print(\"Building likelihood...\")\n",
    "m = ds.ArrayLikelihood([ds.PulsarLikelihood([psr.residuals,\n",
    "                                        ds.makenoise_measurement(psr, psr.noisedict),\n",
    "                                        ds.makegp_ecorr(psr, psr.noisedict),\n",
    "                                        ds.makegp_timing(psr, svd=True),\n",
    "                                        ds.makegp_fourier(psr, ds.powerlaw, components=30, name='rednoise')])\n",
    "                for psr in psrs])\n",
    "print(f\"Done. Parameters: {m.logL.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define priors\n",
    "priors = {\n",
    "    'B1855+09_rednoise_gamma': {'dist': 'uniform', 'min': 0, 'max': 7},\n",
    "    'B1855+09_rednoise_log10_A': {'dist': 'uniform', 'min': -20, 'max': -11},\n",
    "    'B1937+21_rednoise_gamma': {'dist': 'uniform', 'min': 0, 'max': 7},\n",
    "    'B1937+21_rednoise_log10_A': {'dist': 'uniform', 'min': -20, 'max': -11},\n",
    "    'B1953+29_rednoise_gamma': {'dist': 'uniform', 'min': 0, 'max': 7},\n",
    "    'B1953+29_rednoise_log10_A': {'dist': 'uniform', 'min': -20, 'max': -11},\n",
    "}\n",
    "\n",
    "ndim = len(priors)\n",
    "print(f\"Number of dimensions: {ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62747190",
   "metadata": {},
   "source": [
    "## Import BlackJAX interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78989737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')  # Add parent directory to path\n",
    "\n",
    "from src.discoverysamplers.blackjax_interface import DiscoveryBlackJAXBridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dc0c9",
   "metadata": {},
   "source": [
    "## Benchmark function\n",
    "\n",
    "This function runs the nested sampler with different `num_delete` values and measures performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ab9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_nested_sampling(\n",
    "    model, \n",
    "    priors,\n",
    "    n_live: int = 500,\n",
    "    num_delete_values: list = [1, 5, 10, 20, 50, 100],\n",
    "    max_iterations: int = 100,\n",
    "    num_inner_steps: int = None,\n",
    "    seed: int = 42,\n",
    "    warmup_iterations: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark nested sampling with different num_delete values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Discovery model\n",
    "    priors : dict\n",
    "    n_live : int\n",
    "        Number of live points\n",
    "    num_delete_values : list\n",
    "        Values of num_delete to test\n",
    "    max_iterations : int\n",
    "        Maximum iterations per run\n",
    "    num_inner_steps : int, optional\n",
    "        HRSS steps per iteration (default: 5 * ndim)\n",
    "    seed : int\n",
    "        Random seed\n",
    "    warmup_iterations : int\n",
    "        Iterations to run for JIT warmup (not timed)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : Results with timing and efficiency metrics\n",
    "    \"\"\"\n",
    "    import blackjax\n",
    "    import blackjax.ns.utils as ns_utils\n",
    "    \n",
    "    ndim = len([k for k, v in priors.items() if v.get('dist', v[0] if isinstance(v, tuple) else 'uniform') != 'fixed'])\n",
    "    if num_inner_steps is None:\n",
    "        num_inner_steps = ndim * 5\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for num_delete in num_delete_values:\n",
    "        if num_delete > n_live:\n",
    "            print(f\"Skipping num_delete={num_delete} (> n_live={n_live})\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nTesting num_delete={num_delete}...\")\n",
    "        \n",
    "        # Create bridge\n",
    "        bridge = DiscoveryBlackJAXBridge(model, priors)\n",
    "        \n",
    "        # Create sampler\n",
    "        algo = blackjax.nss(\n",
    "            logprior_fn=bridge.log_prior_fn,\n",
    "            loglikelihood_fn=bridge.loglikelihood_fn,\n",
    "            num_delete=num_delete,\n",
    "            num_inner_steps=num_inner_steps,\n",
    "        )\n",
    "        \n",
    "        # Initialize\n",
    "        rng_key = jax.random.PRNGKey(seed)\n",
    "        rng_key, init_key = jax.random.split(rng_key)\n",
    "        unit_samples = jax.random.uniform(init_key, (n_live, bridge.ndim))\n",
    "        initial_particles = jax.vmap(bridge.prior_transform)(unit_samples)\n",
    "        \n",
    "        live = algo.init(initial_particles)\n",
    "        step_fn = jax.jit(algo.step)\n",
    "        \n",
    "        # Warmup (includes JIT compilation)\n",
    "        print(f\"  Warming up ({warmup_iterations} iterations for JIT compilation)...\")\n",
    "        for i in range(warmup_iterations):\n",
    "            rng_key, subkey = jax.random.split(rng_key)\n",
    "            live, _ = step_fn(subkey, live)\n",
    "        \n",
    "        # Block until warmup is complete\n",
    "        jax.block_until_ready(live.logZ)\n",
    "        \n",
    "        # Timed run\n",
    "        print(f\"  Running {max_iterations} timed iterations...\")\n",
    "        dead = []\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        for i in range(max_iterations):\n",
    "            rng_key, subkey = jax.random.split(rng_key)\n",
    "            live, dead_info = step_fn(subkey, live)\n",
    "            dead.append(dead_info)\n",
    "        \n",
    "        # Block until complete\n",
    "        jax.block_until_ready(live.logZ)\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        total_time = end_time - start_time\n",
    "        time_per_iter = total_time / max_iterations\n",
    "        dead_points_per_sec = (num_delete * max_iterations) / total_time\n",
    "        \n",
    "        result = {\n",
    "            'num_delete': num_delete,\n",
    "            'n_live': n_live,\n",
    "            'num_inner_steps': num_inner_steps,\n",
    "            'iterations': max_iterations,\n",
    "            'total_time': total_time,\n",
    "            'time_per_iter': time_per_iter,\n",
    "            'dead_points_per_sec': dead_points_per_sec,\n",
    "            'logZ': float(live.logZ),\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"  Total time: {total_time:.2f}s\")\n",
    "        print(f\"  Time per iteration: {time_per_iter*1000:.2f}ms\")\n",
    "        print(f\"  Dead points/sec: {dead_points_per_sec:.1f}\")\n",
    "        print(f\"  logZ: {result['logZ']:.2f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086b320",
   "metadata": {},
   "source": [
    "## Run the benchmark\n",
    "\n",
    "We'll test different `num_delete` values to find the sweet spot for GPU utilization.\n",
    "\n",
    "**Key insight**: \n",
    "- Higher `num_delete` = more parallelism per iteration\n",
    "- But diminishing returns once GPU is saturated\n",
    "- Memory constraints may limit maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d30680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current device\n",
    "print(f\"Running on: {jax.devices()}\")\n",
    "print(f\"Backend: {jax.default_backend()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ed9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmark with moderate settings\n",
    "# Adjust n_live and num_delete_values based on your GPU memory\n",
    "\n",
    "benchmark_results = benchmark_nested_sampling(\n",
    "    model=m,\n",
    "    priors=priors,\n",
    "    n_live=500,\n",
    "    num_delete_values=[1, 5, 10, 20, 50, 100],\n",
    "    max_iterations=50,\n",
    "    warmup_iterations=5,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890e323",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if benchmark_results:\n",
    "    num_deletes = [r['num_delete'] for r in benchmark_results]\n",
    "    times_per_iter = [r['time_per_iter'] * 1000 for r in benchmark_results]  # ms\n",
    "    dead_per_sec = [r['dead_points_per_sec'] for r in benchmark_results]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Time per iteration\n",
    "    axes[0].plot(num_deletes, times_per_iter, 'o-', markersize=8)\n",
    "    axes[0].set_xlabel('num_delete')\n",
    "    axes[0].set_ylabel('Time per iteration (ms)')\n",
    "    axes[0].set_title('Iteration Time vs num_delete')\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Throughput (dead points per second)\n",
    "    axes[1].plot(num_deletes, dead_per_sec, 'o-', markersize=8, color='green')\n",
    "    axes[1].set_xlabel('num_delete')\n",
    "    axes[1].set_ylabel('Dead points / second')\n",
    "    axes[1].set_title('Throughput vs num_delete')\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nSummary Table:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'num_delete':>12} {'time/iter (ms)':>15} {'dead pts/sec':>15} {'logZ':>12}\")\n",
    "    print(\"-\" * 70)\n",
    "    for r in benchmark_results:\n",
    "        print(f\"{r['num_delete']:>12} {r['time_per_iter']*1000:>15.2f} {r['dead_points_per_sec']:>15.1f} {r['logZ']:>12.2f}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Find optimal\n",
    "    best = max(benchmark_results, key=lambda x: x['dead_points_per_sec'])\n",
    "    print(f\"\\n✓ Optimal num_delete = {best['num_delete']} ({best['dead_points_per_sec']:.1f} dead points/sec)\")\n",
    "else:\n",
    "    print(\"No benchmark results to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b345c0a",
   "metadata": {},
   "source": [
    "## Extended benchmark with more live points\n",
    "\n",
    "If GPU memory allows, try higher `n_live` values for better GPU utilization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbe872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run extended benchmark with more live points\n",
    "# This will take longer but may show better GPU utilization\n",
    "\n",
    "# extended_results = benchmark_nested_sampling(\n",
    "#     model=m,\n",
    "#     priors=priors,\n",
    "#     n_live=1000,\n",
    "#     num_delete_values=[10, 25, 50, 100, 200],\n",
    "#     max_iterations=30,\n",
    "#     warmup_iterations=5,\n",
    "#     seed=42,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106b1d5",
   "metadata": {},
   "source": [
    "## Memory profiling\n",
    "\n",
    "Check GPU memory usage to find the maximum feasible `num_delete`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory estimation\n",
    "def estimate_memory_usage(n_live, ndim, num_inner_steps, dtype_bytes=4):\n",
    "    \"\"\"\n",
    "    Rough estimate of memory usage for nested sampling.\n",
    "    \n",
    "    Main arrays:\n",
    "    - Live particles: n_live * ndim\n",
    "    - Covariance matrix: ndim * ndim\n",
    "    - Intermediate arrays for slice sampling\n",
    "    \"\"\"\n",
    "    particles = n_live * ndim * dtype_bytes\n",
    "    covariance = ndim * ndim * dtype_bytes\n",
    "    # Rough estimate for intermediate computations\n",
    "    intermediate = n_live * ndim * num_inner_steps * dtype_bytes\n",
    "    \n",
    "    total_bytes = particles + covariance + intermediate\n",
    "    return total_bytes / (1024 ** 2)  # MB\n",
    "\n",
    "print(\"Estimated memory usage (MB):\")\n",
    "print(\"-\" * 50)\n",
    "for n_live in [100, 500, 1000, 2000, 5000]:\n",
    "    mem = estimate_memory_usage(n_live, ndim, ndim * 5)\n",
    "    print(f\"  n_live={n_live:>5}: ~{mem:.1f} MB\")\n",
    "\n",
    "print(\"\\nNote: Actual GPU memory usage may be higher due to JAX allocations.\")\n",
    "print(\"Apple Silicon unified memory allows larger allocations than discrete GPUs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a081961",
   "metadata": {},
   "source": [
    "## Full production run\n",
    "\n",
    "Once you've found the optimal `num_delete`, run a full nested sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a93451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full nested sampling with optimal settings\n",
    "# Adjust num_delete based on benchmark results above\n",
    "\n",
    "optimal_num_delete = 20  # Adjust based on your benchmark results\n",
    "\n",
    "bridge = DiscoveryBlackJAXBridge(m, priors)\n",
    "\n",
    "print(f\"Running full nested sampling with num_delete={optimal_num_delete}...\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "results = bridge.run_sampler(\n",
    "    n_live=500,\n",
    "    num_delete=optimal_num_delete,\n",
    "    termination_threshold=-3.0,\n",
    "    seed=42,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")\n",
    "print(f\"logZ = {results['logZ']:.2f} ± {results['logZ_err']:.2f}\")\n",
    "print(f\"Total samples: {results['samples'].shape[0]}\")\n",
    "print(f\"Iterations: {results['n_iterations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02de265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig = bridge.plot_corner()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87bf23e",
   "metadata": {},
   "source": [
    "## Metal GPU Tips\n",
    "\n",
    "### Maximizing Metal GPU performance:\n",
    "\n",
    "1. **Batch size matters**: Higher `num_delete` values allow more parallel work\n",
    "2. **Unified memory advantage**: Apple Silicon shares memory between CPU/GPU, allowing larger `n_live`\n",
    "3. **JIT compilation**: First iteration is slow; subsequent ones benefit from compiled kernels\n",
    "4. **Float32 vs Float64**: Metal works better with float32 (JAX default)\n",
    "\n",
    "### Known Metal limitations:\n",
    "\n",
    "- Some JAX operations may fall back to CPU\n",
    "- Less mature than CUDA backend\n",
    "- Limited profiling tools compared to NVIDIA\n",
    "\n",
    "### To force Metal backend:\n",
    "```python\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'metal')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b380b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
